{% raw %}
groups:
  - name: InstanceState
    rules:
    - alert: InstanceDown
      expr: 'up == 0'
      for: 5m
      labels:
        severity: critical
      annotations:
        description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'
        summary: "{{ $labels.instance }}: Down"

    - alert: "HostCpuLoad > 90%"
      expr: 100 - (avg by(instance, job) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 90
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "{{ $labels.instance }}: CpuLoad > 90%"
        description: "CPU load is > 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: "HostMemoryLoad > 85%"
      expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 15
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: MemoryLoad > 85%"
        description: "Node memory is filling up (< 15% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    
    - alert: "Host network throughput out > 80 MB/s"
      expr: sum by (instance, job) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 80
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "{{ $labels.instance }}: Host network throughput out > 80 MB/s"
        description: "Host network interfaces are probably sending too much data (> 80 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: HostOomKillDetected
      expr: increase(node_vmstat_oom_kill[1m]) > 0
      for: 0m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: Host OOM kill detected"
        description: "OOM kill detected\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: HostNetworkInterfaceSaturated
      expr: (rate(node_network_receive_bytes_total{device!~"^tap.*|^vnet.*|^veth.*|^tun.*"}[1m]) + rate(node_network_transmit_bytes_total{device!~"^tap.*|^vnet.*|^veth.*|^tun.*"}[1m])) / node_network_speed_bytes{device!~"^tap.*|^vnet.*|^veth.*|^tun.*"} > 0.8 < 10000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{{ $labels.instance }}: Host Network Interface Saturated"
        description: "The network interface \"{{ $labels.device }}\" on \"{{ $labels.instance }}\" is getting overloaded.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

 # Please add ignored mountpoints in node_exporter parameters like
   # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
   # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
    
    - alert: "Disk Space < 10% left"
      expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: Disk Space < 10% left"
        description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    
    - alert: "Inodes < 10% left" 
      expr: node_filesystem_files_free / node_filesystem_files * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: Inodes < 10% left"
        description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: "Swap < 20% left" 
      expr: (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: Swap < 20% left"
        description: "Swap is filling up (>80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

 
#container alerts
# This rule can be very noisy in dynamic infra with legitimate container start/stop/deployment.
    - alert: "Container  is down"
      expr: time() - container_last_seen > 60
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: {{ $labels.name }} container is down"
        description: "A container is down for 5 min\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    
      
    - alert: "ContainerCpuUsage is above 90%"
      expr: (sum(rate(container_cpu_usage_seconds_total{name!=""}[3m])) BY (instance, name, job) * 100) > 90
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "{{ $labels.instance }}: {{ $labels.name }} container CPU usage > 90%"
        description: "Container CPU usage is above 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
   
    - alert: "ContainerMemoryUsage is above 85%"
      expr: (sum(container_memory_working_set_bytes{name!=""}) BY (instance, name, job) / sum(container_spec_memory_limit_bytes > 0) BY (instance, name, job) * 100) > 85
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{{ $labels.instance }}: {{ $labels.name }} container Memory usage > 85%"
        description: "Container Memory usage is above 85%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: ContainerHighThrottleRate
      expr: rate(container_cpu_cfs_throttled_seconds_total[3m]) > 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{{ $labels.instance }}: {{ $labels.name }} container high throttle rate"
        description: "Container is being throttled\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: BlackboxProbeFailed
      expr: probe_success == 0
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: Blackbox probe failed"
        description: "Probe failed\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: BlackboxProbeHttpFailure
      expr: probe_http_status_code <= 199 OR probe_http_status_code >= 400
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: {{ $value }} HTTP code"
        description: "HTTP status code is not 200-399\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

    - alert: "Zombie processes is over 5000" 
      expr: node_processes_state{state="Z"} > 5000 OR node_processes_threads_state{thread_state="Z"} > 5000
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "{{ $labels.instance }}: Zombie processes > 5000"
        description: "Instance {{ $labels.instance }}: Processes count: {{ $value | humanize }} zombies during last 10 minutes!"

    - alert: SSLCertificateExpiry
        expr: probe_ssl_earliest_cert_expiry{instance=~"$target"} - time() < 86400
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: {{ $labels.instance }}: SSL/TLS certificate will expire 24h
          description: "The SSL/TLS certificate for {{ $labels.instance }} will expire in {{ humanizeDurationSeconds probe_ssl_cert_expiry_seconds{job=\"blackbox\"} }}. Renew the certificate to avoid service disruptions."
{% endraw %}

{% for db in monitoring_pgsql_dbs %}
    - alert: "Postgresql active connections on DB {{ db['dbname'] }} overhead"
      expr: pg_stat_activity_count{datname="{{ db['dbname'] }}", server="{{ db['host'] }}:{{ db['port'] }}", state="active"} + pg_stat_activity_count{datname="{{ db['dbname'] }}", server="{{ db['host'] }}:{{ db['port'] }}", state="idle"} > 400
      for: 10m
      labels: 
        severity: critical
      annotations:
        summary: {% raw %}"{{ $labels.instance }}{% endraw %}: {{ db['dbname'] }} connections > 400"
        description: {% raw %}"{{ $labels.instance }}{% endraw %}, {{ db['dbname'] }}: Connections: {% raw %}{{ $value | humanize }}{% endraw %} during last 10 minutes!"
{% endfor %}

